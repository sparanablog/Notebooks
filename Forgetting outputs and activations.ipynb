{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forgetting, outputs and activations\n",
    "\n",
    "To start with, I don't really know what I am looking for, just looking. I feel like I need to say that somewhere. \n",
    "\n",
    "Just get some outputs, and play around with pruning levels until it looks like something.\n",
    "\n",
    "I can get everything I need from the first 5 cells of code, I automated some of it, but deleted the loop.\n",
    "\n",
    "Change the targetted class with the remove_classes[] line in the split loader initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initalizing GPU weights\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# This is needed to load the MNIST files for training and testing\n",
    "import pickle\n",
    "\n",
    "# These are the Sparana objects needed to build a model\n",
    "from sparana.model import model\n",
    "from sparana.layers import full_relu_layer\n",
    "from sparana.layers import full_linear_layer\n",
    "from sparana.optimizer import adam_optimizer\n",
    "from sparana.data_loader import split_loader\n",
    "\n",
    "# This is not needed to train and test a simple model, but I am going to demonstrate it here too\n",
    "from sparana.saver import model_saver\n",
    "\n",
    "# These are the extra imports mentioned above\n",
    "from sparana.lobotomizer import lobotomizer\n",
    "import os\n",
    "\n",
    "# Put your own path in here\n",
    "path = 'c:/users/jim/tensorflowtrials'\n",
    "\n",
    "# This initializes the model object, the 2 things that are required are the input size, and a list of layer objects.\n",
    "mymodel = model(input_size = 784, \n",
    "                # These are the layers input as a list, the final layer size is the number of classes the model will have.\n",
    "                layers = [full_relu_layer(size = 1000), \n",
    "                          full_relu_layer(size = 800),\n",
    "                          full_relu_layer(size = 400),\n",
    "                          full_linear_layer(size = 10)],\n",
    "                # This is set automatically, but I keep it in here as a demonstration\n",
    "                comp_type = 'GPU')\n",
    "\n",
    "# Initialize the weights here, after this randomly generated matrices are now in the GPU memory\n",
    "mymodel.initialize_weights('Xavier', bias_constant = 0.1)\n",
    "\n",
    "# Initialize the Adam optimizer, the associated matrices are now in GPU memory\n",
    "opt = adam_optimizer(mymodel, 0.0001, epsilon = 0.001)\n",
    "\n",
    "#Initialize the saver\n",
    "mysaver = model_saver(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9858187458453357\n"
     ]
    }
   ],
   "source": [
    "myloader = split_loader(pickle.load(open('MNIST_train_images.p', 'rb')),\n",
    "                        pickle.load(open('MNIST_train_labels.p', 'rb')),\n",
    "                        pickle.load(open('MNIST_test_images.p', 'rb')),\n",
    "                        pickle.load(open('MNIST_test_labels.p', 'rb')),\n",
    "                        remove_classes = [8],\n",
    "                        maintain_classes = True)\n",
    "# Load the model from pickle file.\n",
    "mysaver.load_model('layers_and_pruning_100000_steps.p')\n",
    "print(mymodel.get_accuracy(myloader.test_data(), myloader.test_labels()))\n",
    "mysaver.store_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lobotomizer\n",
    "\n",
    "lobo = lobotomizer(mymodel)\n",
    "\n",
    "# Load the data to be passed through\n",
    "\n",
    "main_data, main_labels = myloader.random_minibatch(500)\n",
    "removed_data, removed_labels = myloader.removed_minibatch(500)\n",
    "\n",
    "# This is the command that does the work\n",
    "\n",
    "lobo.MAAV_difference(main_data, removed_data)\n",
    "\n",
    "# Same shit lol\n",
    "\n",
    "for i in lobo._weight_stats:\n",
    "    i.data = -i.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with looking at outputs\n",
    "\n",
    "I know what I am looking at here, no extra steps. I can look at 10 output classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9809439397296699\n",
      "0.059548254620123205\n"
     ]
    }
   ],
   "source": [
    "mysaver.restore_model()\n",
    "lobo.prune_smallest(layers = [0, 30000, 30000], print_stats = False, zero_stats = False)\n",
    "data, labels = myloader.removed_test_set()\n",
    "# The zero stats needs to be done here because I am inverting the vales\n",
    "print(mymodel.get_accuracy(myloader.test_data(), myloader.test_labels()))\n",
    "print(mymodel.get_accuracy(data, labels))\n",
    "main = mymodel.outputs(myloader.test_data()[:5])\n",
    "target = mymodel.outputs(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.007  0.006  0.012  0.029 -0.002  0.002  0.011  0.945 -0.011  0.013]\n",
      " [-0.007  0.041  0.792  0.04  -0.012  0.071  0.085  0.046  0.055 -0.023]\n",
      " [-0.017  0.954  0.02   0.02   0.007 -0.01  -0.018 -0.    -0.009  0.021]\n",
      " [ 0.817 -0.005  0.048  0.035  0.022  0.006  0.053  0.042  0.034  0.017]\n",
      " [ 0.011  0.012  0.028  0.021  0.814  0.03   0.033  0.033  0.008  0.023]]\n",
      "[[ 0.143  0.058  0.336  0.135  0.149  0.052  0.035  0.065  0.05   0.072]\n",
      " [ 0.093 -0.    -0.014  0.007  0.288  0.145  0.015 -0.084  0.241  0.367]\n",
      " [ 0.099  0.043  0.119  0.245  0.07   0.133  0.017  0.093  0.112  0.056]\n",
      " [ 0.175 -0.012  0.176  0.063  0.186  0.072 -0.022  0.039  0.104  0.275]\n",
      " [ 0.221  0.018  0.125  0.063  0.06   0.206  0.066  0.065  0.058  0.22 ]\n",
      " [ 0.233 -0.019  0.034  0.111  0.004  0.128  0.072  0.001  0.151  0.387]\n",
      " [ 0.296 -0.018  0.055  0.003  0.116  0.226  0.035 -0.     0.124  0.246]\n",
      " [ 0.173  0.125  0.305 -0.026  0.053  0.277 -0.045  0.063  0.069  0.039]\n",
      " [ 0.216  0.037  0.033 -0.004  0.074  0.181  0.055  0.091  0.239  0.1  ]\n",
      " [ 0.047  0.063  0.021  0.436  0.13   0.05   0.009  0.026  0.075  0.147]]\n",
      "1.0272629\n",
      "1.0543753\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print (np.round(main, 3))\n",
    "print (np.round(target, 3))\n",
    "print(np.mean(np.sum(main, axis = 1)))\n",
    "print(np.mean(np.sum(target, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sums\n",
    "\n",
    "\n",
    " | Zero | 100 | 500 | 1000 | 5000 | 10000 | 15000\n",
    "---|---|---\n",
    "**Target Sum**| 1.001 | 0.952 | 1.036 | 1.054 | 1.093 | 1.069 | 1.15\n",
    "**Target Accuracy**|98.24% | 96.78% | 84.14% | 68.67% | 18.57% | 7.89% | 4.37%\n",
    "**Main Sum**|1.0012 | 1.001 | 1.009 | 1.01 | 1.023 | 1.039 | 1.069\n",
    "**Main Accuracy**| 98.59% | 98.65% | 98.61% | 98.59% | 98.55% | 98.45% |98.22%\n",
    "\n",
    "Taking the means, this will be a small one, so it seems like a good place to put the accuracies, its not that clear from the a plot and it can't hurt. \n",
    "\n",
    "Should this really be a table? I have tables for everything else, onaroll. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect on main outputs\n",
    "\n",
    "# Eights\n",
    "\n",
    "Not going to put it in here, there is a difference, but that I will need to look further into that later. A difference in sums too. \n",
    "\n",
    "# Sevens\n",
    "\n",
    "REally does not change. Not sure how to show this. \n",
    "# 0\n",
    "\n",
    "Zero|\n",
    "---|---|---\n",
    "-0.005 | 0.001 | 1.027 | -0.007 | -0.003 | -0.005 | -0.003  |-0.001 | -0.001 | -0.\n",
    "-0.001 | 0.998 |-0.002 |-0.001 | 0.002| -0.001 |-0. |    0.002 | 0.002| -0.\n",
    "1.026 |-0.001 |-0.003 |-0.005 |-0.002 |-0.004 |-0.002 |-0.001 |-0.004 |-0.002\n",
    "0.001 | 0.004 | 0.004 | 0.003 | 0.972 | 0.003 | 0.003 | 0.006 | 0.004 | 0.004\n",
    "-0.001 | 1.001 |-0.001 | 0.001 | 0.  |  -0.002 | 0.  |   0.001 | 0. |    0.\n",
    "\n",
    "# 15k\n",
    "\n",
    "15,000|\n",
    "---|---|---\n",
    " 0.011 | 0.003 | 1.009 | 0.006 | 0.036 |-0.002 | 0.002 |-0.002 |-0.006 | 0.018\n",
    "-0.01 |  0.98 |  0.012 | 0.005 |-0.002 |-0.003 | 0.01  | 0.012 |-0.006 | 0.033\n",
    "0.972 | 0.044 | 0.015 |-0.015 | 0.034 | 0.001 | 0.013 | 0.004 |-0.012 | 0.034\n",
    "0.021 | 0.044 |-0.005 | 0.033 | 0.81  | 0.044 | 0.049 | 0.03 |  0.014 | 0.015\n",
    "0.003 | 0.945 | 0.014 | 0.012 |-0.  |   0.015 | 0.013 | 0.026 |-0.001 | 0.042\n",
    " \n",
    " The 4th one drops a bit, might be an example that would be forgotten easier if it were targetted. \n",
    " \n",
    " 15,000 is a lot, compare this to the changes seen in the target class. \n",
    " \n",
    " There is no doubt that this will affect the way the model behaves with these classes as well, the question is how much. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect before accuracy drops\n",
    "\n",
    "Parameters Removed | Main Accuracy | Output Values\n",
    "---|---|---\n",
    "zero | 0.9824 | 0.988 | 1.021 | 0.95 | 1.002 | 1.062 | 1.012 | 1.076 | 0.97 | 1.03 | 1.029\n",
    "10 | 0.9776 | 0.938 | 0.966 | 0.917 | 0.992 | 1.045 | 0.962 | 0.999 | 0.914 | 0.982 | 0.95\n",
    "20 | 0.9766 | 0.935 | 0.955 | 0.917 | 0.987 | 1.03 | 0.96 | 0.99 | 0.911 | 0.976 | 0.947\n",
    "50 | 0.9747 | 0.851 | 0.871 | 0.858 | 0.945 | 0.952 | 0.885 | 0.915 | 0.849 | 0.894 | 0.846\n",
    "100 | 0.9684 | 0.753 | 0.767 | 0.818 | 0.915 | 0.879 | 0.821 | 0.863 | 0.797 | 0.807 | 0.825\n",
    "200 | 0.9581 | 0.6 | 0.625 | 0.741 | 0.836 | 0.777 | 0.721 | 0.76 | 0.711 | 0.65 | 0.704\n",
    "300 | 0.9406 | 0.557 | 0.594 | 0.683 | 0.811 | 0.73 | 0.666 | 0.743 | 0.685 | 0.612 | 0.644\n",
    "400 | 0.9202 | 0.501 | 0.545 | 0.659 | 0.747 | 0.664 | 0.595 | 0.757 | 0.624 | 0.568 | 0.611\n",
    "500 | 0.8715 | 0.46 | 0.508 | 0.649 | 0.693 | 0.634 | 0.56 | 0.74 | 0.579 | 0.532 | 0.591\n",
    "\n",
    "\n",
    "Going to go with 7s here. Only the 7 output class, doesn't matter here what else the model might be outputting. \n",
    "\n",
    "The main accuracy is still at that odd point where it is higher than we started with. \n",
    "\n",
    "Pretty obvious here that there is a significant effect early. This is 10 datapoints. Clearly shows there is a difference, but big change overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target class goes down, other classes go up\n",
    "\n",
    "Here I want to demonstrate that pruning does not just reduce the size of the output of the target class. It seems to confuse the model. \n",
    "\n",
    "# A seven\n",
    "\n",
    " | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n",
    "---|---|---\n",
    "**Zero** |-0. |  0.002 | 0.003 | 0.001 | 0.001 | 0.001 | 0.002 | 0.988 | 0.003 | 0. \n",
    "**500** |0.194 | -0.041 | -0.054 | 0.251 | -0.073 | -0.098 | -0.065 | 0.456 | 0.036 | 0.443\n",
    "**1000** |0.236 | -0.056 | 0.001 | 0.362 | -0.08 | -0.106 | -0.096 | 0.341 | 0.04 |  0.433 \n",
    "**2000** |0.204 | -0.106 | 0.086 | 0.379 | -0.091 | -0.099 | -0.076 | 0.179 | 0.123 | 0.384\n",
    "\n",
    "I start with a 7 here because this is what I started with last time. This one is forgotten quite quickly. Here it seems to think that this one is either a 0, 3, 7, or 9. In the last row, 8 seems to be another option, the model is becoming more confused. This particular example is showing results for a relatively small number of parameters being pruned, so I looked at a couple more. \n",
    "\n",
    "# An eight\n",
    "\n",
    " | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n",
    "---|---|---\n",
    "**Zero** | 0.012 | 0.02 | 0.096 | 0.031 | 0.026 | 0.024 | 0.021 | 0.034 | 0.713 | 0.018\n",
    "**500** | 0.003 | -0.016 | 0.313 | 0.141 | -0.033 | -0.036 | 0. | -0.008 | 0.618 | 0.071\n",
    "**1000** | 0.111 | -0.036 | 0.294 | 0.174 | -0.046 | 0.013 | -0.045 | -0.063 | 0.543 | 0.111\n",
    "**2000** | 0.217 | -0.048 | 0.196 | 0.218 | -0.059 | 0.013 | -0.082 | -0.107 | 0.512 | 0.103\n",
    "**5000** | 0.25 | -0.09 | 0.241 | 0.203 | -0.039 | 0.047 | -0.048 | -0.099 | 0.367 | 0.128\n",
    "**15000** | 0.334 | -0.037 | 0.315 | 0.159 | 0.029 | 0.016 | 0.038 | -0.028 | 0.085 | 0.101\n",
    "\n",
    "The model forgot this one quickly. Not as quickly as the 7, but I will get into that in the next experiment. This one could be a 0, 2, 3, 8, or 9. This is different to the 7 above.\n",
    "\n",
    "\n",
    "# A different eight\n",
    "\n",
    " | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n",
    "---|---|---\n",
    "**Zero** |-0.002 | 0. |    0. |   -0.002 | 0. |   -0.004 |-0. |    0.  |   1.01 | -0.002\n",
    "**500** |  0.025 |-0.06 | -0.015 | 0.068 |-0.016 |-0.026 | 0.033 |-0.085 | 0.861 | 0.249\n",
    "**1000** | 0.094 |-0.064 |-0.052 | 0.085 | 0.07 |  0.015 | 0.011 |-0.134 | 0.773 | 0.245\n",
    "**2000** | 0.093 |-0.113 |-0.081 | 0.068 | 0.065 | 0.131 | 0.06 | -0.183 | 0.693 | 0.209\n",
    "**5000** | 0.174 |-0.122 |-0.011 | 0.023 | 0.05 |  0.13 |  0.035 |-0.159 | 0.642 | 0.219\n",
    "**15000** | 0.154 |-0.078 |-0.018 |-0.014 | 0.245 | 0.092 | 0.062 |-0.111 | 0.436 | 0.303\n",
    "\n",
    "This one still registers as an 8 when the accuracy for 8s is 26%. It also starts to think that this is a 4, which doesn't really register for the example above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activations\n",
    "\n",
    "Leaving this in here because I feel like I need to address this somewhere. I was intending to look at activations also, but there turned out to be more than enough to investigate with outputs. It is also less clear what I could learn from activations. I should look into this at some point, but there are more useful things to do first. \n",
    "\n",
    "What I was going to look at was the number of activations in each layer that fire, or pass on a non zero value. I had a brief look and found that there was quite a big difference between different datapoints of the same class, both before and after pruning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
